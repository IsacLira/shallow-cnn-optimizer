{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "86625659-83d8-4537-8e63-1bd7aa814b16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torchvision.transforms import Normalize\n",
    "from ax import optimize\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "class CNNTrainer:\n",
    "    def __init__(self, train_data, batch_size=64, model=None):\n",
    "        self.model = model\n",
    "        # Load the training data\n",
    "        self.train_loader = data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "    def compute_input_size(self, params):\n",
    "        # Add BatchNorm2d layer to standardize input data\n",
    "        x = nn.BatchNorm2d(3)(torch.zeros([1,3,32,32]))\n",
    "        # Pass the input through the sequence of layers\n",
    "        for layer in [\n",
    "                nn.Conv2d(in_channels=3, \n",
    "                          out_channels=params.get('num_filters1'), \n",
    "                          kernel_size=params.get('filter_size1')),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3),\n",
    "                nn.Conv2d(in_channels=params.get('num_filters1'),\n",
    "                          out_channels=params.get('num_filters2'),\n",
    "                          kernel_size=params.get('filter_size2')),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(in_channels=params.get('num_filters2'),\n",
    "                          out_channels=params.get('num_filters3'),\n",
    "                          kernel_size=params.get('filter_size3')),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten()]:\n",
    "            x = layer(x)\n",
    "        input_size = x.shape[0] * x.shape[1]\n",
    "        return input_size\n",
    "\n",
    "    def build_model(self, params):\n",
    "        linear_input = self.compute_input_size(params) \n",
    "        # Define the CNN architecture based on the given parameters\n",
    "        model = nn.Sequential(\n",
    "            nn.BatchNorm2d(3),  # Add BatchNorm2d layer to standardize input data,\n",
    "            nn.Conv2d(in_channels=3, \n",
    "                      out_channels=params.get('num_filters1'), \n",
    "                      kernel_size=params.get('filter_size1')),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.Conv2d(in_channels=params.get('num_filters1'),\n",
    "                      out_channels=params.get('num_filters2'),\n",
    "                      kernel_size=params.get('filter_size2')),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=params.get('num_filters2'),\n",
    "                      out_channels=params.get('num_filters3'),\n",
    "                      kernel_size=params.get('filter_size3')),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(linear_input, 10)\n",
    "        )\n",
    "        return model\n",
    "        \n",
    "        \n",
    "    def fit(self, model, epochs=1):\n",
    "        # Define the loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "        # Train the model\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Running epoch \", epoch)\n",
    "            total, correct = 0,0\n",
    "            for images, labels in self.train_loader:\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            accuracy = correct / total  \n",
    "            print(f\"ACC for epoch {epoch}: \", accuracy)\n",
    "        return model\n",
    "        \n",
    "class CNNPredictor:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        # Evaluate the model on the validation set\n",
    "        data_loader = data.DataLoader(test_data, batch_size=64)\n",
    "        \n",
    "        # Calculate validation accuracy\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in data_loader:\n",
    "                outputs = self.model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        accuracy = correct / total\n",
    "        return labels, accuracy\n",
    "\n",
    "class CNNOptimizer:\n",
    "    def __init__(self, search_space, train_data, val_data, steps=20, epochs=1):\n",
    "        self.epochs = epochs\n",
    "        self.steps = steps\n",
    "        self.search_space = search_space\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "\n",
    "    def evaluate_model(self, parameterization):\n",
    "        try:\n",
    "            print(\"Testing config\", parameterization)\n",
    "            trainer = CNNTrainer(self.train_data)\n",
    "            model = trainer.build_model(parameterization) \n",
    "        except Exception as e:\n",
    "            return {'acc': 0} \n",
    "        \n",
    "        print(\"CONFIG Valida\")\n",
    "        model = trainer.fit(model, epochs=self.epochs)\n",
    "        predictor = CNNPredictor(model)\n",
    "        _, accuracy = predictor.predict(self.val_data)\n",
    "        print(\"ACC during eval\", accuracy)\n",
    "        # Return the validation accuracy as the objective value to optimize\n",
    "        return {'acc': accuracy}\n",
    "\n",
    "    def optimize(self):\n",
    "        \n",
    "        constraints = [\"num_filters1 <= num_filters2\",    \n",
    "                       \"num_filters2 <= num_filters3\",   \n",
    "                       \"filter_size1 >= filter_size2\",   \n",
    "                       \"filter_size2 >= filter_size3\",   \n",
    "                       # \"pool_size1 <= pool_size2\",   \n",
    "                       # \"pool_size2 <= filter_size2\"\n",
    "                      ]    \n",
    "\n",
    "        best_parameters, best_values, experiment, model = optimize(\n",
    "            parameters=self.search_space,\n",
    "            evaluation_function=self.evaluate_model,\n",
    "            parameter_constraints=constraints,\n",
    "            objective_name='acc',\n",
    "            minimize=False,\n",
    "            total_trials=self.steps\n",
    "        )\n",
    "\n",
    "        print('Best parameters:', best_parameters)\n",
    "        print('Best validation accuracy:', best_values[0])\n",
    "        \n",
    "        return best_parameters, best_values, experiment, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "fdbb701d-a09b-4e8c-bb29-d7615dc13339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-24 16:29:18] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='num_filters1', parameter_type=INT, range=[12, 32]), RangeParameter(name='filter_size1', parameter_type=INT, range=[3, 5]), RangeParameter(name='num_filters2', parameter_type=INT, range=[12, 32]), RangeParameter(name='filter_size2', parameter_type=INT, range=[3, 5]), RangeParameter(name='num_filters3', parameter_type=INT, range=[12, 32]), RangeParameter(name='filter_size3', parameter_type=INT, range=[3, 5])], parameter_constraints=[OrderConstraint(num_filters1 <= num_filters2), OrderConstraint(num_filters2 <= num_filters3), OrderConstraint(filter_size2 <= filter_size1), OrderConstraint(filter_size3 <= filter_size2)]).\n",
      "[INFO 03-24 16:29:18] ax.modelbridge.dispatch_utils: Using Models.GPEI since there are more ordered parameters than there are categories for the unordered categorical parameters.\n",
      "[INFO 03-24 16:29:18] ax.modelbridge.dispatch_utils: Calculating the number of remaining initialization trials based on num_initialization_trials=None max_initialization_trials=None num_tunable_parameters=6 num_trials=None use_batch_trials=False\n",
      "[INFO 03-24 16:29:18] ax.modelbridge.dispatch_utils: calculated num_initialization_trials=12\n",
      "[INFO 03-24 16:29:18] ax.modelbridge.dispatch_utils: num_completed_initialization_trials=0 num_remaining_initialization_trials=12\n",
      "[INFO 03-24 16:29:18] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 12 trials, GPEI for subsequent trials]). Iterations after 12 will take longer to generate due to model-fitting.\n",
      "[INFO 03-24 16:29:18] ax.service.managed_loop: Started full optimization with 10 steps.\n",
      "[INFO 03-24 16:29:18] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 03-24 16:29:18] ax.service.managed_loop: Running optimization trial 2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing config {'num_filters1': 12, 'filter_size1': 5, 'num_filters2': 18, 'filter_size2': 5, 'num_filters3': 27, 'filter_size3': 4}\n",
      "Testing config {'num_filters1': 20, 'filter_size1': 4, 'num_filters2': 22, 'filter_size2': 4, 'num_filters3': 23, 'filter_size3': 3}\n",
      "CONFIG Valida\n",
      "Running epoch  0\n",
      "ACC for epoch 0:  0.29643926788685526\n",
      "Running epoch  1\n",
      "ACC for epoch 1:  0.4206322795341098\n",
      "Running epoch  2\n",
      "ACC for epoch 2:  0.4620299500831947\n",
      "Running epoch  3\n",
      "ACC for epoch 3:  0.4961730449251248\n",
      "Running epoch  4\n",
      "ACC for epoch 4:  0.5249251247920134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-24 16:29:55] ax.service.managed_loop: Running optimization trial 3...\n",
      "[INFO 03-24 16:29:55] ax.service.managed_loop: Running optimization trial 4...\n",
      "[INFO 03-24 16:29:55] ax.service.managed_loop: Running optimization trial 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC during eval 0.5178511845178512\n",
      "Testing config {'num_filters1': 18, 'filter_size1': 4, 'num_filters2': 18, 'filter_size2': 4, 'num_filters3': 27, 'filter_size3': 4}\n",
      "Testing config {'num_filters1': 18, 'filter_size1': 4, 'num_filters2': 18, 'filter_size2': 4, 'num_filters3': 21, 'filter_size3': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-24 16:29:55] ax.service.managed_loop: Running optimization trial 6...\n",
      "[INFO 03-24 16:29:56] ax.service.managed_loop: Running optimization trial 7...\n",
      "[INFO 03-24 16:29:56] ax.service.managed_loop: Running optimization trial 8...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing config {'num_filters1': 15, 'filter_size1': 5, 'num_filters2': 22, 'filter_size2': 5, 'num_filters3': 26, 'filter_size3': 4}\n",
      "Testing config {'num_filters1': 16, 'filter_size1': 5, 'num_filters2': 20, 'filter_size2': 5, 'num_filters3': 27, 'filter_size3': 3}\n",
      "Testing config {'num_filters1': 13, 'filter_size1': 4, 'num_filters2': 17, 'filter_size2': 4, 'num_filters3': 28, 'filter_size3': 4}\n",
      "Testing config {'num_filters1': 17, 'filter_size1': 4, 'num_filters2': 17, 'filter_size2': 4, 'num_filters3': 21, 'filter_size3': 3}\n",
      "CONFIG Valida\n",
      "Running epoch  0\n",
      "ACC for epoch 0:  0.2849251247920133\n",
      "Running epoch  1\n",
      "ACC for epoch 1:  0.41710482529118137\n",
      "Running epoch  2\n",
      "ACC for epoch 2:  0.4523793677204659\n",
      "Running epoch  3\n",
      "ACC for epoch 3:  0.47966722129783695\n",
      "Running epoch  4\n",
      "ACC for epoch 4:  0.5023627287853577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 03-24 16:30:45] ax.service.managed_loop: Running optimization trial 9...\n",
      "[INFO 03-24 16:30:45] ax.service.managed_loop: Running optimization trial 10...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC during eval 0.5055055055055055\n",
      "Testing config {'num_filters1': 12, 'filter_size1': 5, 'num_filters2': 21, 'filter_size2': 4, 'num_filters3': 21, 'filter_size3': 4}\n",
      "Testing config {'num_filters1': 19, 'filter_size1': 4, 'num_filters2': 19, 'filter_size2': 4, 'num_filters3': 30, 'filter_size3': 4}\n",
      "Best parameters: {'num_filters1': 20, 'filter_size1': 4, 'num_filters2': 22, 'filter_size2': 4, 'num_filters3': 23, 'filter_size3': 3}\n",
      "Best validation accuracy: {'acc': 0.5178511845178512}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load the CIFAR10 dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "val_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Define the search space\n",
    "\n",
    "def subsample(data, p=0.3):\n",
    "    mask = np.random.rand(len(data)) <= p\n",
    "    mask = np.array(range(len(data)))[mask]\n",
    "    subset = torch.utils.data.Subset(data, mask)\n",
    "    return subset\n",
    "\n",
    "sub_train  = subsample(train_dataset)\n",
    "sub_val  = subsample(val_dataset)\n",
    "\n",
    "search_space = [\n",
    "    {\"name\": \"num_filters1\", \"type\": \"range\", \"bounds\": [12, 32], \"value_type\":\"int\"},\n",
    "    {\"name\": \"filter_size1\", \"type\": \"range\", \"bounds\": [3, 5], \"value_type\":\"int\"},\n",
    "    {\"name\": \"num_filters2\", \"type\": \"range\", \"bounds\": [12, 32], \"value_type\":\"int\"},\n",
    "    {\"name\": \"filter_size2\", \"type\": \"range\", \"bounds\": [3, 5], \"value_type\":\"int\"},\n",
    "    {\"name\": \"num_filters3\", \"type\": \"range\", \"bounds\": [12, 32], \"value_type\":\"int\"},\n",
    "    {\"name\": \"filter_size3\", \"type\": \"range\", \"bounds\": [3, 5], \"value_type\":\"int\"},\n",
    "]\n",
    "# Initialize the CNNOptimizer\n",
    "optimizer = CNNOptimizer(search_space, sub_train, sub_val, steps=10, epochs=5)\n",
    "\n",
    "# Run the optimization\n",
    "best_parameters, best_values, experiment, model = optimizer.optimize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "30566eb0-4449-4b71-8ecb-a13e47cb431e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'num_filters1': 20,\n",
       "  'filter_size1': 4,\n",
       "  'num_filters2': 22,\n",
       "  'filter_size2': 4,\n",
       "  'num_filters3': 23,\n",
       "  'filter_size3': 3},\n",
       " ({'acc': 0.5178511845178512}, {'acc': {'acc': nan}}))"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters, best_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "3326a6ce-8edb-4606-b04a-2beb49b7632f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arm_name</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>trial_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_0</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.517851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_0</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_0</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_0</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5_0</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6_0</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7_0</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.505506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8_0</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9_0</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  arm_name metric_name      mean  sem  trial_index\n",
       "0      0_0         acc  0.000000  NaN            0\n",
       "1      1_0         acc  0.517851  NaN            1\n",
       "2      2_0         acc  0.000000  NaN            2\n",
       "3      3_0         acc  0.000000  NaN            3\n",
       "4      4_0         acc  0.000000  NaN            4\n",
       "5      5_0         acc  0.000000  NaN            5\n",
       "6      6_0         acc  0.000000  NaN            6\n",
       "7      7_0         acc  0.505506  NaN            7\n",
       "8      8_0         acc  0.000000  NaN            8\n",
       "9      9_0         acc  0.000000  NaN            9"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = experiment.fetch_data()\n",
    "data.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "9ffe39f8-6dc7-4ee8-85e0-2b21d375bd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch  0\n",
      "Running epoch  1\n",
      "Running epoch  2\n",
      "Running epoch  3\n",
      "Running epoch  4\n",
      "Running epoch  5\n",
      "Running epoch  6\n",
      "Running epoch  7\n",
      "Running epoch  8\n",
      "Running epoch  9\n",
      "Running epoch  10\n",
      "Running epoch  11\n",
      "Running epoch  12\n",
      "Running epoch  13\n",
      "Running epoch  14\n",
      "Running epoch  15\n",
      "Running epoch  16\n",
      "Running epoch  17\n",
      "Running epoch  18\n",
      "Running epoch  19\n",
      "Running epoch  20\n",
      "Running epoch  21\n",
      "Running epoch  22\n",
      "Running epoch  23\n",
      "Running epoch  24\n",
      "Running epoch  25\n",
      "Running epoch  26\n",
      "Running epoch  27\n",
      "Running epoch  28\n",
      "Running epoch  29\n",
      "Running epoch  30\n",
      "Running epoch  31\n",
      "Running epoch  32\n",
      "Running epoch  33\n",
      "Running epoch  34\n",
      "Running epoch  35\n",
      "Running epoch  36\n",
      "Running epoch  37\n",
      "Running epoch  38\n",
      "Running epoch  39\n",
      "Running epoch  40\n",
      "Running epoch  41\n",
      "Running epoch  42\n",
      "Running epoch  43\n",
      "Running epoch  44\n",
      "Running epoch  45\n",
      "Running epoch  46\n",
      "Running epoch  47\n",
      "Running epoch  48\n",
      "Running epoch  49\n"
     ]
    }
   ],
   "source": [
    "trainer = CNNTrainer(train_dataset)\n",
    "model = trainer.build_model(best_parameters) \n",
    "model = trainer.fit(model, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "65c23bbe-4e00-43a0-96aa-c47d28121a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = CNNPredictor(model)\n",
    "_, accuracy = predictor.predict(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "39e152a1-3bf1-4f2d-87d4-9e701713bc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6977"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "26eec2a0-2613-49b9-a312-dee806a03bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique, counts = np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "d908cf76-4755-4cfd-8fa2-dc8ebf37bd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1472, 1493, 1496, 1443, 1500, 1504, 1443, 1547, 1453, 1463])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9870ddef-8ff2-484e-986d-80e32611154e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
