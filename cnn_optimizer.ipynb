{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86625659-83d8-4537-8e63-1bd7aa814b16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torchvision.transforms import Normalize\n",
    "from ax import optimize\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     total += labels.size(0)\n",
    "#     correct += (predicted == labels).sum().item()\n",
    "# accuracy = correct / total  \n",
    "# print(f\"ACC for epoch {epoch}: \", accuracy)\n",
    "\n",
    "class CNNTrainer:\n",
    "    def __init__(self, train_data, val_data=None, batch_size=64, model=None, patience=5):\n",
    "        self.patience = patience\n",
    "        self.model = model\n",
    "        # Load the training data\n",
    "        self.train_loader = data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "        if val_data: \n",
    "            self.val_loader = data.DataLoader(train_data, batch_size=batch_size)\n",
    "            \n",
    "    def compute_input_size(self, params):\n",
    "        # Add BatchNorm2d layer to standardize input data\n",
    "        x = nn.BatchNorm2d(3)(torch.zeros([1,3,32,32]))\n",
    "        pool1 = eval(params.get(\"pool1\"))\n",
    "        pool2 = eval(params.get(\"pool2\"))        \n",
    "        # Pass the input through the sequence of layers\n",
    "        for layer in [\n",
    "                nn.Conv2d(in_channels=3, \n",
    "                          out_channels=params.get('num_filters1'), \n",
    "                          kernel_size=params.get('filter_size1')),\n",
    "                nn.ReLU(),\n",
    "                pool1(kernel_size=params.get(\"kernel_pool1\")),\n",
    "                nn.Conv2d(in_channels=params.get('num_filters1'),\n",
    "                          out_channels=params.get('num_filters2'),\n",
    "                          kernel_size=params.get('filter_size2')),\n",
    "                nn.ReLU(),\n",
    "                pool2(kernel_size=params.get(\"kernel_pool2\")),\n",
    "                nn.Conv2d(in_channels=params.get('num_filters2'),\n",
    "                          out_channels=params.get('num_filters3'),\n",
    "                          kernel_size=params.get('filter_size3')),\n",
    "                nn.ReLU(),\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(params.get('num_filters3'),\n",
    "                              params.get('num_filters3'), \n",
    "                              kernel_size=1),\n",
    "                    nn.Sigmoid()),            \n",
    "                nn.Flatten()]:\n",
    "            x = layer(x)\n",
    "        input_size = x.shape[0] * x.shape[1]\n",
    "        return input_size\n",
    "\n",
    "    def build_model(self, params):\n",
    "        linear_input = self.compute_input_size(params) \n",
    "        # Define the CNN architecture based on the given parameters\n",
    "        pool1 = eval(params.get(\"pool1\"))\n",
    "        pool2 = eval(params.get(\"pool2\"))\n",
    "        print(\"linear_input\", linear_input)\n",
    "        model = nn.Sequential(\n",
    "            nn.BatchNorm2d(3),  # Add BatchNorm2d layer to standardize input data,\n",
    "            nn.Conv2d(in_channels=3, \n",
    "                      out_channels=params.get('num_filters1'), \n",
    "                      kernel_size=params.get('filter_size1')),\n",
    "            nn.ReLU(),\n",
    "            pool1(kernel_size=params.get(\"kernel_pool1\")),\n",
    "            nn.Conv2d(in_channels=params.get('num_filters1'),\n",
    "                      out_channels=params.get('num_filters2'),\n",
    "                      kernel_size=params.get('filter_size2')),\n",
    "            nn.ReLU(),\n",
    "            pool2(kernel_size=params.get(\"kernel_pool2\")),\n",
    "            nn.Conv2d(in_channels=params.get('num_filters2'),\n",
    "                      out_channels=params.get('num_filters3'),\n",
    "                      kernel_size=params.get('filter_size3')),\n",
    "            nn.ReLU(),\n",
    "           # Define the attention mechanism\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(params.get('num_filters3'),\n",
    "                          params.get('num_filters3'), \n",
    "                          kernel_size=1),\n",
    "                nn.Sigmoid()),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(linear_input, 10)\n",
    "        )\n",
    "        return model\n",
    "        \n",
    "        \n",
    "    def fit(self, model, lr=0.001, epochs=1):\n",
    "        # Initialize weights with Xavier initialization\n",
    "                \n",
    "        for m in model.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)      \n",
    "                \n",
    "        # Define the loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        # Set the number of threads for multi-threading\n",
    "        torch.set_num_threads(8)\n",
    "        \n",
    "        # Initialize some variables for early stopping\n",
    "        best_loss = float('inf')\n",
    "        counter = 0  # Counter for number of epochs without improvement\n",
    "        \n",
    "        # Train the model\n",
    "        model.train()\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Running epoch \", epoch)\n",
    "            total, correct = 0,0\n",
    "            for images, labels in self.train_loader:\n",
    "                images, labels = images.to(device='cpu'), labels.to(device='cpu')\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            # Validate your model\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0\n",
    "                for x, y in self.val_loader:\n",
    "                    y_pred = model(x)\n",
    "                    val_loss += criterion(y_pred, y).item()\n",
    "                val_loss /= len(self.val_loader)\n",
    "            print('Val loss: ', val_loss)\n",
    "            # Check for improvement\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter >= self.patience:\n",
    "                    print(f\"Early stopping on epoch {epoch}\")\n",
    "                    break\n",
    "        return model\n",
    "        \n",
    "class CNNPredictor:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        # Evaluate the model on the validation set\n",
    "        data_loader = data.DataLoader(test_data, batch_size=64)\n",
    "        \n",
    "        # Calculate validation accuracy\n",
    "        correct, total  = 0, 0\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in data_loader:\n",
    "                outputs = self.model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        accuracy = correct / total\n",
    "        return labels, accuracy\n",
    "\n",
    "\n",
    "class CNNOptimizer:\n",
    "    def __init__(self, search_space, train_data, val_data, steps=20, epochs=1):\n",
    "        self.epochs = epochs\n",
    "        self.steps = steps\n",
    "        self.search_space = search_space\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "\n",
    "    def evaluate_model(self, parameterization):\n",
    "        batch_size = parameterization.get(\"batch_size\")\n",
    "        lr = parameterization.get(\"lr\")\n",
    "        \n",
    "        try:\n",
    "            print(\"Testing config\", parameterization)\n",
    "            trainer = CNNTrainer(self.train_data, batch_size=batch_size)\n",
    "            model = trainer.build_model(parameterization) \n",
    "        except Exception as e:\n",
    "            logging.error(e)\n",
    "            return {'acc': 0} \n",
    "        \n",
    "        print(\"CONFIG Valida\")\n",
    "        model = trainer.fit(model, lr=lr, epochs=self.epochs)\n",
    "        predictor = CNNPredictor(model)\n",
    "        _, accuracy = predictor.predict(self.val_data)\n",
    "        print(\"ACC during eval\", accuracy)\n",
    "        # Return the validation accuracy as the objective value to optimize\n",
    "        return {'acc': accuracy}\n",
    "\n",
    "    def optimize(self):\n",
    "        \n",
    "        constraints = [\"num_filters1 <= num_filters2\",    \n",
    "                       \"num_filters2 <= num_filters3\",   \n",
    "                       \"filter_size1 >= filter_size2\",   \n",
    "                       \"filter_size2 >= filter_size3\"  \n",
    "                      ]    \n",
    "\n",
    "        best_parameters, best_values, experiment, model = optimize(\n",
    "            parameters=self.search_space,\n",
    "            evaluation_function=self.evaluate_model,\n",
    "            parameter_constraints=constraints,\n",
    "            objective_name='acc',\n",
    "            minimize=False,\n",
    "            total_trials=self.steps\n",
    "        )\n",
    "\n",
    "        print('Best parameters:', best_parameters)\n",
    "        print('Best validation accuracy:', best_values[0])\n",
    "        \n",
    "        return best_parameters, best_values, experiment, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fdbb701d-a09b-4e8c-bb29-d7615dc13339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load the CIFAR10 dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Define the search space\n",
    "\n",
    "def split_train_val(data, ptrain=0.3, pval=0.2):\n",
    "    train_mask = np.random.rand(len(data)) <= ptrain\n",
    "    val_mask = np.random.rand(len(data)) >= (1-pval)\n",
    "    index = np.array(range(len(data)))\n",
    "    train_id, test_id = index[train_mask], index[val_mask]\n",
    "    train = torch.utils.data.Subset(data, train_id)\n",
    "    test = torch.utils.data.Subset(data, test_id)\n",
    "    return train, test\n",
    "\n",
    "train, val = split_train_val(train_dataset)\n",
    "\n",
    "search_space = [\n",
    "    {\"name\": \"num_filters1\", \"type\": \"range\", \"bounds\": [12, 32], \"value_type\":\"int\"},\n",
    "    {\"name\": \"filter_size1\", \"type\": \"range\", \"bounds\": [3, 5], \"value_type\":\"int\"},\n",
    "    {\"name\": \"num_filters2\", \"type\": \"range\", \"bounds\": [12, 32], \"value_type\":\"int\"},\n",
    "    {\"name\": \"filter_size2\", \"type\": \"range\", \"bounds\": [3, 5], \"value_type\":\"int\"},\n",
    "    {\"name\": \"num_filters3\", \"type\": \"range\", \"bounds\": [12, 32], \"value_type\":\"int\"},\n",
    "    {\"name\": \"filter_size3\", \"type\": \"range\", \"bounds\": [3, 5], \"value_type\":\"int\"},\n",
    "    {\"name\": \"pool1\", \"type\": \"choice\", \"is_ordered\": False,\n",
    "     \"values\": [\"nn.AvgPool2d\", \"nn.MaxPool2d\"]},\n",
    "    {\"name\": \"pool2\", \"type\": \"choice\", \"is_ordered\": False, \n",
    "     \"values\": [\"nn.AvgPool2d\", \"nn.MaxPool2d\"]},\n",
    "    {\"name\": \"kernel_pool1\", \"type\": \"range\", \"bounds\": [2, 3], \"value_type\":\"int\"},\n",
    "    {\"name\": \"kernel_pool2\", \"type\": \"range\", \"bounds\": [2, 3], \"value_type\":\"int\"},\n",
    "    {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [1e-5,1e-2], \"value_type\":\"float\"},\n",
    "    {\"name\": \"batch_size\", \"type\": \"range\", \"bounds\": [16, 128], \"value_type\":\"int\"},    \n",
    "]\n",
    "\n",
    "# Initialize the CNNOptimizer\n",
    "optimizer = CNNOptimizer(search_space, train, val, steps=120, epochs=2)\n",
    "\n",
    "# Run the optimization\n",
    "best_parameters, best_values, experiment, model = optimizer.optimize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "30566eb0-4449-4b71-8ecb-a13e47cb431e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'num_filters1': 16,\n",
       "  'filter_size1': 5,\n",
       "  'num_filters2': 23,\n",
       "  'filter_size2': 5,\n",
       "  'num_filters3': 28,\n",
       "  'filter_size3': 4,\n",
       "  'kernel_pool1': 2,\n",
       "  'kernel_pool2': 2,\n",
       "  'lr': 0.0051422473539197155,\n",
       "  'batch_size': 73,\n",
       "  'pool1': 'nn.AvgPool2d',\n",
       "  'pool2': 'nn.AvgPool2d'},\n",
       " ({'acc': 0.44478208681781845}, {'acc': {'acc': 0.00010064481711331273}}))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters, best_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3326a6ce-8edb-4606-b04a-2beb49b7632f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arm_name</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>trial_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.429545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_0</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.422530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_0</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.371016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_0</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.438765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_0</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  arm_name metric_name      mean  sem  trial_index\n",
       "0      0_0         acc  0.429545  NaN            0\n",
       "1      1_0         acc  0.422530  NaN            1\n",
       "2      2_0         acc  0.371016  NaN            2\n",
       "3      3_0         acc  0.438765  NaN            3\n",
       "4      4_0         acc  0.000000  NaN            4"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = experiment.fetch_data()\n",
    "data.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3bc53d1d-c616-4bf4-b3a8-2c6625bf1b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9810b1c-3216-416c-9104-5a2d80a4da76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (2): ReLU()\n",
      "  (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (4): Conv2d(16, 23, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (5): ReLU()\n",
      "  (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (7): Conv2d(23, 28, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (8): ReLU()\n",
      "  (9): Sequential(\n",
      "    (0): Conv2d(28, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (10): Flatten(start_dim=1, end_dim=-1)\n",
      "  (11): Linear(in_features=112, out_features=10, bias=True)\n",
      ")\n",
      "tensor([[ 0.8756, -5.5353,  1.8794,  0.1591,  0.2256, -0.5847, -5.5011, -1.3562,\n",
      "         -1.4498, -5.1926]], grad_fn=<AddmmBackward0>)\n",
      "BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected 4D input (got 2D input)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-487f6b5418f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mariner/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mariner/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_input_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# exponential_average_factor is set to self.momentum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mariner/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36m_check_input_dim\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_input_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expected 4D input (got {}D input)\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: expected 4D input (got 2D input)"
     ]
    }
   ],
   "source": [
    "x= torch.zeros([1,3,32,32])\n",
    "\n",
    "for m in model.modules():\n",
    "    print(m)\n",
    "    x = m(x)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ffe39f8-6dc7-4ee8-85e0-2b21d375bd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_input 112\n",
      "Running epoch  0\n",
      "Val loss:  1.5491171064063007\n",
      "Running epoch  1\n",
      "Val loss:  1.370190205914011\n",
      "Running epoch  2\n",
      "Val loss:  1.294030192456254\n",
      "Running epoch  3\n",
      "Val loss:  1.217041905336014\n",
      "Running epoch  4\n",
      "Val loss:  1.1468653453333504\n",
      "Running epoch  5\n",
      "Val loss:  1.1017187319464397\n",
      "Running epoch  6\n",
      "Val loss:  1.089891591281298\n",
      "Running epoch  7\n",
      "Val loss:  1.0189920145153346\n",
      "Running epoch  8\n",
      "Val loss:  0.992445466941192\n",
      "Running epoch  9\n",
      "Val loss:  0.9562430723929536\n",
      "Running epoch  10\n",
      "Val loss:  0.9406902184216153\n",
      "Running epoch  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fc3b2d89160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/isac/miniconda3/envs/mariner/lib/python3.8/logging/__init__.py\", line 227, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 330532, 330540) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/mariner/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mariner/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-7fcc48aea7b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-ef331b51c994>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, lr, epochs)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running epoch \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mariner/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mariner/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mariner/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mariner/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 330532, 330540) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "train, val = split_train_val(train_dataset, ptrain=0.7, pval=0.3)\n",
    "\n",
    "best_parameters= {'num_filters1': 16,\n",
    "  'filter_size1': 5,\n",
    "  'num_filters2': 23,\n",
    "  'filter_size2': 5,\n",
    "  'num_filters3': 28,\n",
    "  'filter_size3': 4,\n",
    "  'kernel_pool1': 2,\n",
    "  'kernel_pool2': 2,\n",
    "  'lr': 0.01, # 0.0051422473539197155,\n",
    "  'batch_size': 73,\n",
    "  'pool1': 'nn.AvgPool2d',\n",
    "  'pool2': 'nn.AvgPool2d'}\n",
    "\n",
    "trainer = CNNTrainer(train, val)\n",
    "model = trainer.build_model(best_parameters) \n",
    "model = trainer.fit(model, epochs=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65c23bbe-4e00-43a0-96aa-c47d28121a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7790674134556987"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = CNNPredictor(model)\n",
    "labels, accuracy = predictor.predict(val)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "26eec2a0-2613-49b9-a312-dee806a03bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique, counts = np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d908cf76-4755-4cfd-8fa2-dc8ebf37bd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7fcd4b953f20>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9870ddef-8ff2-484e-986d-80e32611154e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the model: 21907\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters in the model: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37ddd8e-5fb4-4dd8-b235-245ebc796930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
